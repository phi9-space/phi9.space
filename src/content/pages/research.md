---
title: Research
description: A living index of our navigation research, experiments, and publications exploring physical AI across subterranean, urban, and planetary environments.
heroSubtitle: Field notes from the edge of autonomous navigation.
updated: 2024-05-18
---

# Research & Experiments

## Networked Sensing Underground

We prototype resilient comms meshes that keep perception models synced in subterranean environments where bandwidth collapses. Our latest deployments cover:

- Acoustic + UWB fusion for drift-resistant odometry
- Opportunistic relays using robot-to-robot handoffs
- Latency-tolerant map stitching with sparse local keyframes

## Planetary-Scale Simulation

We maintain a synthetic planet pipeline for testing navigation stacks against varied gravity, terrain composition, and light scattering. The dataset currently spans 47 generated worlds with:

- Procedural mineral caves with dynamic collapses
- Dust storms that occlude lidar returns and saturate cameras
- Solar glare sweep patterns for polar orbits

> Every research artifact is captured as Markdown in Obsidian, then surfaced via Astro content collections for reproducible dissemination.

## Interface Prototyping

The Human â†” AI toggle lets us present narrative context alongside raw Markdown so operators can jump between briefings and structured data dumps. Next iterations include:

- Timeline overlays for multi-agent missions
- AI-assisted diffing of Markdown updates across deployments
- WebGL ASCII shader showing sensor coverage in real time
